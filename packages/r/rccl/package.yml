# yaml-language-server: $schema=/usr/share/ypkg/schema/schema.json
name: rccl
version: 2.20.5
release: 5
source:
    - https://github.com/ROCm/rccl/archive/refs/tags/rocm-6.2.4.tar.gz: 12a04743ed89a74b4a08aa046b6a549d385e15d6866042fd41eac8f085f50eea
homepage: https://github.com/ROCmSoftwarePlatform/rccl
license: MIT
component: programming.library
summary: ROCm Communication Collectives Library (RCCL)
description: |
    RCCL (pronounced "Rickle") is a stand-alone library of standard collective communication routines for GPUs, implementing all-reduce, all-gather, reduce, broadcast, reduce-scatter, gather, scatter, and all-to-all. There is also initial support for direct GPU-to-GPU send and receive operations. It has been optimized to achieve high bandwidth on platforms using PCIe, xGMI as well as networking using InfiniBand Verbs or TCP/IP sockets. RCCL supports an arbitrary number of GPUs installed in a single node or multiple nodes, and can be used in either single- or multi-process (e.g., MPI) applications.
builddeps:
    - rocm-cmake
    - rocm-hip
    - rocm-hipify
    - rocm-core-devel
environment: |
    export CXXFLAGS="${CXXFLAGS/-D_FORTIFY_SOURCE=2 -fstack-protector-strong --param=ssp-buffer-size=32/-fcf-protection=none}"

    export ROCM_PATH=/usr
    export CMAKE_PREFIX_PATH=/usr/lib64/llvm-rocm
    export HIP_CLANG_PATH=/usr/lib64/llvm-rocm/bin
    export DEVICE_LIB_PATH=/usr/lib64/amdgcn/bitcode

    # rccl tries to define its own toolchain
    export CC="$ROCM_PATH/bin/hipcc"
    export CXX="$ROCM_PATH/bin/hipcc"
setup: |
    %cmake_ninja -L \
      -DROCM_PATH=$ROCM_PATH \
      -DCMAKE_INSTALL_LIBDIR=lib%LIBSUFFIX% \
      -DROCM_SYMLINK_LIBS=OFF \
      -DBUILD_STATIC=OFF \
      -DBUILD_TESTS=OFF \
      -DGPU_TARGETS="%AMDGPUTARGETS%" \
      -DAMDGPU_TARGETS="%AMDGPUTARGETS%"
build: |
    %ninja_build
install: |
    %ninja_install
